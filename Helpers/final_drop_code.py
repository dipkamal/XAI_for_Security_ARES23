# -*- coding: utf-8 -*-
"""Final_drop_code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jTuzdP0xJdiqqD8ehu543XAfyNMbqH_C
"""

!pip install captum

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import torch.utils.data as utils
import torch.utils.data as td
torch.manual_seed(1234)

import pandas as pd
from sklearn.model_selection import train_test_split
import numpy as np
from torch.utils.data import Dataset, DataLoader
from sklearn.preprocessing import LabelEncoder

import tensorflow as tf

# imports from captum library
from captum.attr import (
    IntegratedGradients,
    DeepLift,
    GradientShap,
    NoiseTunnel,
    Saliency,
    InputXGradient,
    Occlusion,
)
from captum.attr import DeepLiftShap, KernelShap, LimeBase
import matplotlib.pyplot as plt
from captum._utils.models.linear_model import SkLearnLinearModel

# Load datasets
path_to_csv = "contagio-all.csv"
df = pd.read_csv(path_to_csv)
df =df.drop(['filename'], axis=1)

# Pandas dataframes to numpy arrays
X = df.drop(["class"], axis=1).values
Y = df["class"].values

from sklearn.preprocessing import normalize

binary_encoding = False 
if binary_encoding: 
    X[np.where(data!= 0)] = 1
else:
    X = normalize(X, 'max', axis=0)

train_features, test_features, train_labels, test_labels = train_test_split(
  X, Y, test_size=0.3,random_state=42)

class NNModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.linear1 = nn.Linear(135, 135)
        self.sigmoid1 = nn.Sigmoid()
        self.linear2 = nn.Linear(135, 100)
        self.sigmoid2 = nn.Sigmoid()
        self.linear3 = nn.Linear(100, 8)
        self.sigmoid3 = nn.Sigmoid()
        self.linear4 = nn.Linear(8, 2)
        self.softmax = nn.Softmax(dim=1)

    def forward(self, x):
        lin1_out = self.linear1(x)
        sigmoid_out1 = self.sigmoid1(lin1_out)
        sigmoid_out2 = self.sigmoid2(self.linear2(sigmoid_out1))
        sigmoid_out3 = self.sigmoid3(self.linear3(sigmoid_out2))
        return self.softmax(self.linear4(sigmoid_out3))
        # return self.linear4(sigmoid_out3)

net = NNModel()

criterion = nn.CrossEntropyLoss()
num_epochs = 300

optimizer = torch.optim.Adam(net.parameters(), lr=0.001)
input_tensor = torch.from_numpy(train_features).type(torch.FloatTensor)
label_tensor = torch.from_numpy(train_labels)


for epoch in range(num_epochs):
    output = net(input_tensor)
    loss = criterion(output, label_tensor)
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    if epoch % 20 == 0:
        print("Epoch {}/{} => Loss: {:.2f}".format(epoch + 1, num_epochs, loss.item()))

path = "PDFClassifierFinal.pth"
net = NNModel()
net.load_state_dict(torch.load(path))
net.eval()

path_to_csv = "contagio-all.csv"
data = pd.read_csv(path_to_csv, dtype=str, delimiter=',',)
data = data.drop(['filename'], axis=1)
data = data.drop(['class'], axis=1)
feature_names = data.columns
x_axis_data = np.arange(test_features.shape[1])

x_axis_data

x_axis_data_labels = list(map(lambda idx: feature_names[idx], x_axis_data))


x_axis_data_labels

def similarity_kernel(original_input, perturbed_input, perturbed_interpretable_input,**kwargs):
    kernel_width = kwargs["kernel_width"]
    l2_dist = torch.norm(original_input - perturbed_input)
    return torch.exp(- (l2_dist**2) / (kernel_width**2))

def perturb_func(original_input,**kwargs):
    return original_input + torch.randn_like(original_input)

def to_interp_transform(curr_sample, original_inp,**kwargs):
    return curr_sample


def main_func(exp_method):

  tp_ip = [exp_method]

  sa = Saliency(net)
  ks = KernelShap(net)
  ig = IntegratedGradients(net)
  dl = DeepLift(net)
  gs = GradientShap(net)
  sa = Saliency(net)
  ixg = InputXGradient(net)
  occ = Occlusion(net)
  dls = DeepLiftShap(net)


  test_input_tensor = torch.from_numpy(test_features).type(torch.FloatTensor)
  test_labels_tensor =  torch.from_numpy(test_labels)


  test_feature = test_input_tensor[0:600]
  test_label = test_labels_tensor[0:600]

  new_test_label = []
  new_test_feature = []
  for i in range(len(test_label)):
      if (test_label[i] == 1):
          new_test_label.append(test_label[i])
          new_test_feature.append(test_feature[i])



  new_test_feature_tensor = torch.stack(new_test_feature)
  new_test_label_tensor = torch.stack(new_test_label)


  la_la_list = []
  for i in range(0,len(new_test_feature_tensor)):


    ip = new_test_feature_tensor[i]
    op = new_test_label_tensor[i]


    new_test_feature_tensor_temp = ip.unsqueeze(0)
    new_test_label_tensor_temp = op.unsqueeze(0)
    


    methods = tp_ip

    for explainers in methods:

      if explainers == "Saliency":
        sa_attr_test = sa.attribute(new_test_feature_tensor_temp, target = new_test_label_tensor_temp)

        sa_attr_test_sum = sa_attr_test.detach().numpy().sum(0)
        sa_attr_test_norm_sum = sa_attr_test_sum / np.linalg.norm(sa_attr_test_sum, ord=1)

        sa_top_50_ind = np.argsort(sa_attr_test_norm_sum)[-50:]
        
        sa_top_50_ind = np.flip(sa_top_50_ind)

      
      elif explainers == "Integrated Gradients":

        ig_attr_test = ig.attribute(new_test_feature_tensor_temp, target = new_test_label_tensor_temp, n_steps=50)
        ig_attr_test_sum = ig_attr_test.detach().numpy().sum(0)
        ig_attr_test_norm_sum = ig_attr_test_sum / np.linalg.norm(ig_attr_test_sum, ord=1)

        ig_top_50_ind = np.argsort(ig_attr_test_norm_sum)[-50:]
        ig_top_50_ind = np.flip(ig_top_50_ind)

      elif explainers == "DeepLift":

        dl_attr_test = dl.attribute(new_test_feature_tensor_temp, target = new_test_label_tensor_temp,)
        dl_attr_test_sum = dl_attr_test.detach().numpy().sum(0)
        dl_attr_test_norm_sum = dl_attr_test_sum / np.linalg.norm(dl_attr_test_sum, ord=1)


        dl_top_50_ind = np.argsort(dl_attr_test_norm_sum)[-50:]
        dl_top_50_ind = np.flip(dl_top_50_ind)

 

      elif explainers == "GradientShap":

        gs_attr_test = gs.attribute(new_test_feature_tensor_temp, target = new_test_label_tensor_temp, baselines = input_tensor[1:50])
        gs_attr_test_sum = gs_attr_test.detach().numpy().sum(0)
        gs_attr_test_norm_sum = gs_attr_test_sum / np.linalg.norm(gs_attr_test_sum, ord=1)
    
        gs_top_50_ind = np.argsort(gs_attr_test_norm_sum)[-50:]
        gs_top_50_ind = np.flip(gs_top_50_ind)

      
      
      elif explainers == "InputXGradient":
        
        inputXgradient_attr_test = ixg.attribute(new_test_feature_tensor_temp, target = new_test_label_tensor_temp,)
        inputxgradient_attr_test_sum = inputXgradient_attr_test.detach().numpy().sum(0)
        inputxgradient_attr_test_norm_sum = inputxgradient_attr_test_sum / np.linalg.norm(inputxgradient_attr_test_sum, ord=1)



        ixg_top_50_ind = np.argsort(inputxgradient_attr_test_norm_sum)[-50:]
        ixg_top_50_ind = np.flip(ixg_top_50_ind)



      elif explainers == "Occlusion":
        occl_attr_test = occ.attribute(new_test_feature_tensor_temp, sliding_window_shapes=(3,))
        occl_attr_test_sum = occl_attr_test.detach().numpy().sum(0)
        occl_attr_test_norm_sum = occl_attr_test_sum / np.linalg.norm(occl_attr_test_sum, ord=1)


        occ_top_50_ind = np.argsort(occl_attr_test_norm_sum)[-50:]
        occ_top_50_ind = np.flip(occ_top_50_ind)

      elif explainers == "Shap":

        ks_attr_test = ks.attribute(new_test_feature_tensor_temp, target = new_test_label_tensor_temp)

        ks_attr_test_sum = ks_attr_test.detach().numpy().sum(0)
        ks_attr_test_norm_sum = ks_attr_test_sum / np.linalg.norm(ks_attr_test_sum, ord=1)
      

        ks_top_50_ind = np.argsort(ks_attr_test_norm_sum)[-50:]
        ks_top_50_ind = np.flip(ks_top_50_ind)


      elif explainers == "Lime":
        

        lime_attr = LimeBase(net,
                         SkLearnLinearModel("linear_model.Ridge"),
                         similarity_func=similarity_kernel,
                         perturb_func=perturb_func,
                         perturb_interpretable_space=False,
                         from_interp_rep_transform=None,
                         to_interp_rep_transform=to_interp_transform)
        
        lime_attr = lime_attr.attribute(new_test_feature_tensor_temp, target = new_test_label_tensor_temp, kernel_width=1.1)
        lime_attr_test_sum = lime_attr.detach().numpy().sum(0)
        lime_attr_test_norm_sum = lime_attr_test_sum / np.linalg.norm(lime_attr_test_sum, ord=1)

        lime_top_50_ind = np.argsort(lime_attr_test_norm_sum)[-50:]
        lime_top_50_ind = np.flip(lime_top_50_ind)






      for j in range(50):
        temp = []
        temp.append(i)
        temp.append(explainers)

        if explainers == "Integrated Gradients":
          top_15_ind = ig_top_50_ind
        elif explainers == "Saliency":
          top_15_ind = sa_top_50_ind
        elif explainers == "DeepLift":
          top_15_ind = dl_top_50_ind
        elif explainers == "GradientShap":
          top_15_ind = gs_top_50_ind
        elif explainers == "InputXGradient":
          top_15_ind = ixg_top_50_ind
        elif explainers == "Occlusion":
          top_15_ind = occ_top_50_ind
        elif explainers == "Shap":
          top_15_ind = ks_top_50_ind
        elif explainers == "Lime":
          top_15_ind = lime_top_50_ind
     



        indices_to_replace = top_15_ind[0:j]

        for idx in indices_to_replace:
          new_test_feature_tensor_temp[0][idx] = 0


        out_probs = net(new_test_feature_tensor_temp).detach().numpy()
        out_classes = np.argmax(out_probs, axis=1)

        top_class_idx = np.argmax(out_probs)
        top_class_prob = out_probs[0][top_class_idx]

        temp.append(j)
        temp.append(out_classes[0])
        temp.append(top_class_prob)
        la_la_list.append(temp)


  df = pd.DataFrame(la_la_list)

  return df

def append_df(existing_df, new_df):
    if existing_df.empty:
        return new_df
    else:
        return existing_df.append(new_df, ignore_index=True)

import warnings
warnings.filterwarnings('ignore')

# List of explanation methods to evaluate
methods = ["Integrated Gradients", "Saliency", "DeepLift", "GradientShap", "InputXGradient", "Occlusion", "Shap", "Lime"]

# Create an empty DataFrame to store the results
temp = pd.DataFrame()

# Loop through each explanation method and run the main function to generate results
for i in methods:
    df = main_func(i) # Call the main_func() function for the current explanation method
    temp = append_df(temp, df) # Append the results to the temp DataFrame
    df.tail() # Print the last 5 rows of the results DataFrame

    df.to_csv("results_data_final.csv") # Save the results to a CSV file

  # Read the results from the CSV file into a pandas DataFrame
    path_to_csv = "results_data_final.csv"
    df = pd.read_csv(path_to_csv)

    # Filter the DataFrame to only include rows where prediction is 1
    df.loc[df['3'] == 0, '4'] = 0

    # Filter the DataFrame to only include rows where the number of features removed is less than or equal to 21
    df = df[df['2']<=21]

    # Calculate the average probability for each combination of no_of_features_removed and method
    avg_probs = df.groupby(['2', '1'])['4'].mean().reset_index()



df = temp


# print(df.shape)
# Filter the DataFrame to only include rows where prediction is 1
df.loc[df[3] == 0, 4] = 0
df = df[df[2]<=10]


# Calculate the average probability for each combination of no_of_features_removed and method
avg_probs = df.groupby([2, 1])[4].mean().reset_index()

# avg_probs['smoothed_probability'] = avg_probs.groupby('1')['4'].rolling(window=3, center=True).mean().reset_index(drop=True)

# Plot the results
fig, ax = plt.subplots(figsize=(8, 6))
for method, group in avg_probs.groupby(1):
    ax.plot(group[2], group[4], label=method)
ax.set_xlabel('No. of Features Removed')
ax.set_ylabel('Probability of prediction')
# ax.set_title('Average Probability vs. No. of Features Removed for Different Methods ')
ax.set_ylim(0.0, 1)
ax.legend()


plt.show()